{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4141d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebea14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=42)\n",
    "y = y.reshape(-1, 1)  # Reshape y to have 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "821de096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbaaf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "950e0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ANN model for regression\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054c7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e861780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 15ms/step - loss: 37816.6367 - val_loss: 36402.4297\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 37646.0039 - val_loss: 36197.7188\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 37352.4219 - val_loss: 35796.8359\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 36764.6602 - val_loss: 35043.8672\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 35719.1328 - val_loss: 33705.3516\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 33909.2578 - val_loss: 31656.1133\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 31247.5215 - val_loss: 28636.7305\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 27502.5645 - val_loss: 24727.8008\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 22928.2051 - val_loss: 20046.3340\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 17699.4512 - val_loss: 15193.1377\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 12611.1416 - val_loss: 10414.7754\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 8115.1567 - val_loss: 6565.0234\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 4732.4497 - val_loss: 3794.0476\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2673.2900 - val_loss: 2014.0056\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1470.1517 - val_loss: 1202.4407\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 950.1393 - val_loss: 786.8024\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 688.9759 - val_loss: 581.7466\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 537.1519 - val_loss: 460.2101\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 433.6346 - val_loss: 387.8562\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 361.9400 - val_loss: 336.0621\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 307.4507 - val_loss: 293.4066\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 270.0633 - val_loss: 263.8159\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 238.8180 - val_loss: 237.5935\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 223.6318 - val_loss: 226.7087\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 211.5510 - val_loss: 212.7201\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 201.7702 - val_loss: 208.4512\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 196.7522 - val_loss: 200.9781\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 190.2273 - val_loss: 195.2631\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 186.5650 - val_loss: 192.0334\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 182.2856 - val_loss: 192.1003\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 176.8038 - val_loss: 186.2697\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 173.2839 - val_loss: 183.5630\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 170.5543 - val_loss: 184.1183\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 166.0396 - val_loss: 178.0595\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 161.7080 - val_loss: 184.1924\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 157.8075 - val_loss: 175.8133\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 155.5710 - val_loss: 166.8946\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 150.4970 - val_loss: 173.1851\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 148.6681 - val_loss: 171.5592\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 144.8248 - val_loss: 165.0435\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 141.0907 - val_loss: 162.3463\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 137.9791 - val_loss: 160.1272\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 135.2565 - val_loss: 158.9436\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 132.1310 - val_loss: 161.9201\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 128.5897 - val_loss: 155.1202\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 125.3079 - val_loss: 154.1729\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 122.3830 - val_loss: 155.4928\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 120.8502 - val_loss: 147.1694\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 117.5678 - val_loss: 151.4928\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 114.0030 - val_loss: 150.8212\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 111.6422 - val_loss: 147.4440\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 109.4531 - val_loss: 140.9857\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 106.8569 - val_loss: 149.6425\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 104.3688 - val_loss: 136.5180\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 103.5831 - val_loss: 143.1676\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 101.8644 - val_loss: 146.2441\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 99.3369 - val_loss: 132.0007\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 94.7308 - val_loss: 140.4245\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 91.6498 - val_loss: 132.5175\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 90.0587 - val_loss: 130.4836\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 87.9181 - val_loss: 132.4822\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 85.4744 - val_loss: 133.3997\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 84.6708 - val_loss: 128.0899\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 82.1614 - val_loss: 136.6248\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 79.5390 - val_loss: 123.3105\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 77.0744 - val_loss: 126.0384\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 74.9732 - val_loss: 127.6641\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 73.7693 - val_loss: 125.8197\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 72.1829 - val_loss: 117.3296\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 70.0964 - val_loss: 119.2108\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 68.3165 - val_loss: 122.7616\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 66.8140 - val_loss: 116.9978\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 64.1552 - val_loss: 118.2176\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 62.7513 - val_loss: 116.7189\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 60.9356 - val_loss: 117.4786\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 59.4995 - val_loss: 114.4158\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 58.1296 - val_loss: 111.5711\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 57.5062 - val_loss: 118.0249\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 6ms/step - loss: 55.7504 - val_loss: 109.6029\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 54.0715 - val_loss: 110.3677\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 52.8653 - val_loss: 104.5089\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 50.9753 - val_loss: 108.6181\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 50.3905 - val_loss: 105.9827\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 49.6861 - val_loss: 101.7693\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 47.5317 - val_loss: 105.3770\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 45.8956 - val_loss: 106.0785\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 45.2252 - val_loss: 97.9706\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 43.4628 - val_loss: 102.3310\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 42.6705 - val_loss: 99.5387\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 41.6624 - val_loss: 103.3232\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 40.3393 - val_loss: 96.0823\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 39.7100 - val_loss: 100.1776\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 39.4311 - val_loss: 96.5412\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 37.0810 - val_loss: 99.5778\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 36.7064 - val_loss: 92.7289\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 35.9057 - val_loss: 96.7069\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 35.1009 - val_loss: 92.6550\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 34.0660 - val_loss: 93.4488\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 33.3270 - val_loss: 96.5921\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 32.4331 - val_loss: 88.4511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244d9b97880>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e7defc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 87.9458\n",
      "Test MSE: 87.94576263427734\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test MSE: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77e9d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "387cbc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-319.2385   ],\n",
       "       [-368.20837  ],\n",
       "       [ 357.8035   ],\n",
       "       [-267.7145   ],\n",
       "       [ 204.58774  ],\n",
       "       [ 206.68584  ],\n",
       "       [ 402.61212  ],\n",
       "       [-129.637    ],\n",
       "       [ -65.88706  ],\n",
       "       [-277.965    ],\n",
       "       [-201.01956  ],\n",
       "       [-380.90262  ],\n",
       "       [ -64.155304 ],\n",
       "       [ -49.844524 ],\n",
       "       [  76.15521  ],\n",
       "       [  79.41771  ],\n",
       "       [-187.92021  ],\n",
       "       [-193.42027  ],\n",
       "       [ -58.179134 ],\n",
       "       [ 469.77747  ],\n",
       "       [-144.96718  ],\n",
       "       [ 114.39622  ],\n",
       "       [ 224.83597  ],\n",
       "       [  51.358425 ],\n",
       "       [ 251.74257  ],\n",
       "       [  -4.1767697],\n",
       "       [  31.1298   ],\n",
       "       [ 433.33795  ],\n",
       "       [  49.82242  ],\n",
       "       [  38.507275 ],\n",
       "       [ -30.932093 ],\n",
       "       [  89.37215  ],\n",
       "       [  74.74327  ],\n",
       "       [-115.95702  ],\n",
       "       [   9.8148575],\n",
       "       [-169.3029   ],\n",
       "       [ -82.33884  ],\n",
       "       [ 307.31094  ],\n",
       "       [  40.532284 ],\n",
       "       [ 171.52922  ],\n",
       "       [-213.51408  ],\n",
       "       [ 110.36338  ],\n",
       "       [ -14.725019 ],\n",
       "       [-287.5036   ],\n",
       "       [ -42.7528   ],\n",
       "       [  -2.72868  ],\n",
       "       [-296.15457  ],\n",
       "       [ 197.17494  ],\n",
       "       [   2.1768777],\n",
       "       [-134.71716  ],\n",
       "       [ -14.377911 ],\n",
       "       [ 128.18018  ],\n",
       "       [ -96.51611  ],\n",
       "       [-554.82697  ],\n",
       "       [ 173.73857  ],\n",
       "       [ 329.1438   ],\n",
       "       [ 138.67752  ],\n",
       "       [   9.253603 ],\n",
       "       [ -30.442366 ],\n",
       "       [ -46.79439  ],\n",
       "       [ 243.5514   ],\n",
       "       [  31.951153 ],\n",
       "       [ 230.05775  ],\n",
       "       [-171.86366  ],\n",
       "       [-113.71278  ],\n",
       "       [  24.213238 ],\n",
       "       [-143.79236  ],\n",
       "       [-435.69098  ],\n",
       "       [ -31.085125 ],\n",
       "       [  25.936033 ],\n",
       "       [ -34.757824 ],\n",
       "       [ 145.00818  ],\n",
       "       [ 181.72548  ],\n",
       "       [-178.58525  ],\n",
       "       [ 175.64835  ],\n",
       "       [ -91.41592  ],\n",
       "       [-325.7435   ],\n",
       "       [ 185.48204  ],\n",
       "       [ -19.218222 ],\n",
       "       [ -75.09977  ],\n",
       "       [-306.85898  ],\n",
       "       [  73.40089  ],\n",
       "       [-304.82175  ],\n",
       "       [ 451.55328  ],\n",
       "       [-160.5942   ],\n",
       "       [ 131.11269  ],\n",
       "       [-154.84053  ],\n",
       "       [ -86.61439  ],\n",
       "       [-286.54883  ],\n",
       "       [  63.738735 ],\n",
       "       [ 270.39038  ],\n",
       "       [  70.44203  ],\n",
       "       [ 172.46085  ],\n",
       "       [-279.16495  ],\n",
       "       [ 229.97725  ],\n",
       "       [  -6.4462304],\n",
       "       [ 173.35251  ],\n",
       "       [  66.80094  ],\n",
       "       [-115.95536  ],\n",
       "       [-130.01663  ],\n",
       "       [  37.856915 ],\n",
       "       [-250.27724  ],\n",
       "       [ -73.77267  ],\n",
       "       [ 405.00342  ],\n",
       "       [-155.71602  ],\n",
       "       [ 239.1356   ],\n",
       "       [ 312.48187  ],\n",
       "       [ -46.959133 ],\n",
       "       [-121.7192   ],\n",
       "       [ 113.29897  ],\n",
       "       [  13.3046875],\n",
       "       [ 148.95544  ],\n",
       "       [-101.90735  ],\n",
       "       [  55.93534  ],\n",
       "       [  14.644655 ],\n",
       "       [-316.85095  ],\n",
       "       [-212.6301   ],\n",
       "       [ -51.285496 ],\n",
       "       [-120.29357  ],\n",
       "       [   9.212198 ],\n",
       "       [ 188.28627  ],\n",
       "       [ 268.96945  ],\n",
       "       [-252.4889   ],\n",
       "       [  20.388613 ],\n",
       "       [ 296.01566  ],\n",
       "       [ 130.36974  ],\n",
       "       [ 103.8885   ],\n",
       "       [  89.923164 ],\n",
       "       [ 122.85151  ],\n",
       "       [  22.202105 ],\n",
       "       [ 208.92047  ],\n",
       "       [ -85.94495  ],\n",
       "       [  -2.3699362],\n",
       "       [ -82.78654  ],\n",
       "       [ -81.849144 ],\n",
       "       [ 400.6388   ],\n",
       "       [-214.72818  ],\n",
       "       [ -66.66147  ],\n",
       "       [  64.76808  ],\n",
       "       [ 216.27542  ],\n",
       "       [  59.907207 ],\n",
       "       [-126.731514 ],\n",
       "       [ 128.6941   ],\n",
       "       [-197.16972  ],\n",
       "       [ 186.55814  ],\n",
       "       [-340.9931   ],\n",
       "       [ 250.75232  ],\n",
       "       [ 270.6147   ],\n",
       "       [ 116.90515  ],\n",
       "       [  85.19784  ],\n",
       "       [ -94.289085 ],\n",
       "       [ 139.79033  ],\n",
       "       [-312.4475   ],\n",
       "       [ 160.94223  ],\n",
       "       [ -60.475735 ],\n",
       "       [  94.95224  ],\n",
       "       [ 245.78624  ],\n",
       "       [ 306.3877   ],\n",
       "       [-175.84378  ],\n",
       "       [ -21.283115 ],\n",
       "       [  -6.6827054],\n",
       "       [-249.14491  ],\n",
       "       [ 286.73895  ],\n",
       "       [ 166.0549   ],\n",
       "       [ 352.5869   ],\n",
       "       [ 126.28921  ],\n",
       "       [-133.15694  ],\n",
       "       [ 132.3754   ],\n",
       "       [ 368.55002  ],\n",
       "       [ -37.332584 ],\n",
       "       [  -0.6939433],\n",
       "       [-346.47314  ],\n",
       "       [ -69.61747  ],\n",
       "       [-155.07188  ],\n",
       "       [ 275.58545  ],\n",
       "       [-114.29508  ],\n",
       "       [-205.48077  ],\n",
       "       [-149.50987  ],\n",
       "       [ 174.07875  ],\n",
       "       [  -1.8267138],\n",
       "       [ 113.22713  ],\n",
       "       [-218.32149  ],\n",
       "       [ -84.40372  ],\n",
       "       [ -44.01041  ],\n",
       "       [ 142.34895  ],\n",
       "       [-189.52539  ],\n",
       "       [-238.73811  ],\n",
       "       [-211.54901  ],\n",
       "       [-125.44433  ],\n",
       "       [ 296.91824  ],\n",
       "       [-370.32706  ],\n",
       "       [-181.63033  ],\n",
       "       [ -36.765926 ],\n",
       "       [ 336.08713  ],\n",
       "       [   3.6967447],\n",
       "       [-150.26767  ],\n",
       "       [ 216.69783  ],\n",
       "       [-159.93594  ],\n",
       "       [ 211.5353   ],\n",
       "       [ 130.28944  ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcf265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
